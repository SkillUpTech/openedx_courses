{
  "start": [
    860, 
    4456, 
    7125, 
    11613, 
    17316, 
    24650, 
    29554, 
    36400, 
    39718, 
    43306, 
    47940, 
    50320, 
    52270, 
    55340, 
    57470, 
    59500, 
    63359, 
    67300, 
    72690, 
    76140, 
    77550, 
    79830, 
    82640, 
    84800, 
    90310, 
    95243, 
    99110, 
    102950, 
    106640, 
    108580, 
    113350, 
    118630, 
    121560, 
    125850, 
    128147
  ], 
  "end": [
    4456, 
    7125, 
    11613, 
    17316, 
    22666, 
    29554, 
    34470, 
    39718, 
    43306, 
    46820, 
    50320, 
    51110, 
    55340, 
    57470, 
    59500, 
    63359, 
    67300, 
    69440, 
    76140, 
    77550, 
    79830, 
    82640, 
    84800, 
    90310, 
    95243, 
    97570, 
    102950, 
    106640, 
    107140, 
    113350, 
    117610, 
    121560, 
    124030, 
    128147, 
    132647
  ], 
  "text": [
    "A brief recap of what we did in logistic regression.", 
    "In logistic regression,", 
    "we took the image of the handwritten digit,", 
    "flattened it out and then built individual classifiers", 
    "like ten of those tuned to detect each of the digits.", 
    "We did it in one go using a matrix that we learned of", 
    "the weights here and the corresponding biases.", 
    "The output of the model was passed through,", 
    "initially we trained with a sigmoid function,", 
    "which is also called an activation function.", 
    "And then we also tried with another one which", 
    "is the soft max.", 
    "Now the soft max one works really well,", 
    "especially with categorical data.", 
    "And we use that most often.", 
    "However, there is a role for these activation functions in", 
    "building higher-order models where we layer", 
    "one layer of these neurons on top of the other.", 
    "So, now why do you want to do logistic regression was very,", 
    "very clear.", 
    "And we were able to train a model.", 
    "However, if you did your assignment, and", 
    "you trained a logistic regression model,", 
    "you can use the MNIST data and see what accuracies you get.", 
    "You probably would get something like 7 to 8% error rate,", 
    "or 92 to 93% accuracy.", 
    "Which means if you've got 100 digits,", 
    "you would see about 7 or 8 of them being misclassified.", 
    "Is that good?", 
    "Well, if you are writing 100 digits on your post offices", 
    "using this logistic regression model to classify that", 
    "automatically, there's gonna be a large number", 
    "of letters that are gonna be delivered in the wrong place.", 
    "Let's see how we can fix or", 
    "update our model that would reduce the error rate."
  ]
}