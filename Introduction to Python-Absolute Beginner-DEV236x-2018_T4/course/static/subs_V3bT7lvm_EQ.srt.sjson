{
  "start": [
    260, 
    3711, 
    6022, 
    10488, 
    12911, 
    16688, 
    20044, 
    25044, 
    28155, 
    31644, 
    33955, 
    36111, 
    40200, 
    45755, 
    49933, 
    54333, 
    57822, 
    61733, 
    64577, 
    67440, 
    71933, 
    75533, 
    77200, 
    80488, 
    85111, 
    90044, 
    93510, 
    100333, 
    105022, 
    110088, 
    114955, 
    119155, 
    122088, 
    124511, 
    126733, 
    130244, 
    132840, 
    137288, 
    140220, 
    145333, 
    149355, 
    152911, 
    155577, 
    161733, 
    166088, 
    169911, 
    172550, 
    174880, 
    177977, 
    180533, 
    185130, 
    189466, 
    191555, 
    199955, 
    206422, 
    209511, 
    214644, 
    218266, 
    221266, 
    225911, 
    231955, 
    236577, 
    239222, 
    241333, 
    247022, 
    250977, 
    256222, 
    260200, 
    264911, 
    268266, 
    272577, 
    276370, 
    282155, 
    287200, 
    291288, 
    297711, 
    299577, 
    301800, 
    305570, 
    309740, 
    313300, 
    317120, 
    322190, 
    326790, 
    329680, 
    334450, 
    340460, 
    344820, 
    348110, 
    354040, 
    359150, 
    363120, 
    366560, 
    369900, 
    372810, 
    374930, 
    377100, 
    379470, 
    386680, 
    391280, 
    393870, 
    397040, 
    404190, 
    408530, 
    411500, 
    414000, 
    418030, 
    421790, 
    424450, 
    428200, 
    436830, 
    440740, 
    444620, 
    447180, 
    449650, 
    452670, 
    455640, 
    458540, 
    461690, 
    465620, 
    470000, 
    480330, 
    489040, 
    493010, 
    498430, 
    500380, 
    504670, 
    508390, 
    511610, 
    514140, 
    517630, 
    520890, 
    526400, 
    528510, 
    532160, 
    536390, 
    541610, 
    546920, 
    549750, 
    555070, 
    559200, 
    564970, 
    569600, 
    577170, 
    580140, 
    584470, 
    587050, 
    589950, 
    591690, 
    594040, 
    596100, 
    599960, 
    603320, 
    607830, 
    616670, 
    621430, 
    625450, 
    628100, 
    634960, 
    638750, 
    641180, 
    646890, 
    654990, 
    660910, 
    665290, 
    666970, 
    671150, 
    671970, 
    681320, 
    687580, 
    692000, 
    694750, 
    697750, 
    701520, 
    705410, 
    712740, 
    715550, 
    720000, 
    726200, 
    728860, 
    734550, 
    736010, 
    741080, 
    744980, 
    756230, 
    762040, 
    766140, 
    769120, 
    771430, 
    775840, 
    783100, 
    784800, 
    786800, 
    790490, 
    795170, 
    802790, 
    804630, 
    809260, 
    814290, 
    816080, 
    822310, 
    826840, 
    834800, 
    841820, 
    843570, 
    849290, 
    851960, 
    858830, 
    862830, 
    866660, 
    874530, 
    877940, 
    880820, 
    885790, 
    889670, 
    899410, 
    903290, 
    906290, 
    909570
  ], 
  "end": [
    3688, 
    5955, 
    10422, 
    12800, 
    16660, 
    19977, 
    23088, 
    28088, 
    31520, 
    33770, 
    35940, 
    39880, 
    45600, 
    49866, 
    54288, 
    57755, 
    61688, 
    64533, 
    67400, 
    71888, 
    75460, 
    77133, 
    80422, 
    85066, 
    89933, 
    93400, 
    98977, 
    104950, 
    109977, 
    114888, 
    119088, 
    122000, 
    124444, 
    126666, 
    130155, 
    132800, 
    137244, 
    140130, 
    145311, 
    149288, 
    152844, 
    155555, 
    161711, 
    166044, 
    169911, 
    172511, 
    174800, 
    177911, 
    180511, 
    185066, 
    189422, 
    191466, 
    199830, 
    206370, 
    209488, 
    214577, 
    218244, 
    221222, 
    225866, 
    231755, 
    236480, 
    239060, 
    241220, 
    246930, 
    250950, 
    256177, 
    260133, 
    264888, 
    268200, 
    272488, 
    276333, 
    282066, 
    287133, 
    291170, 
    297666, 
    299511, 
    301644, 
    304930, 
    308740, 
    312820, 
    316840, 
    321800, 
    326720, 
    329390, 
    334180, 
    340290, 
    343300, 
    347300, 
    353630, 
    358880, 
    362550, 
    366140, 
    369900, 
    372600, 
    374930, 
    377100, 
    379360, 
    386550, 
    391120, 
    393750, 
    396760, 
    403640, 
    406650, 
    410910, 
    414000, 
    418030, 
    421790, 
    423710, 
    428170, 
    435440, 
    440600, 
    444340, 
    447170, 
    449480, 
    452100, 
    455470, 
    457980, 
    461600, 
    465160, 
    469620, 
    480330, 
    489020, 
    492650, 
    497960, 
    499880, 
    504460, 
    507980, 
    511580, 
    513930, 
    517630, 
    520860, 
    525660, 
    528510, 
    531620, 
    535200, 
    540540, 
    546590, 
    549440, 
    555070, 
    558640, 
    564970, 
    569600, 
    577170, 
    580140, 
    584470, 
    587050, 
    589950, 
    591690, 
    594040, 
    596100, 
    599960, 
    603320, 
    607830, 
    615180, 
    621400, 
    624480, 
    628100, 
    633420, 
    638750, 
    641180, 
    646890, 
    653280, 
    660910, 
    665290, 
    666970, 
    671150, 
    671970, 
    679590, 
    685670, 
    691470, 
    694750, 
    697750, 
    701520, 
    705410, 
    711320, 
    715550, 
    717550, 
    726200, 
    728860, 
    734550, 
    736010, 
    741080, 
    744980, 
    756230, 
    762040, 
    766140, 
    769120, 
    771430, 
    775840, 
    781730, 
    784800, 
    786800, 
    790490, 
    795170, 
    802790, 
    804630, 
    809260, 
    814290, 
    816080, 
    822310, 
    826840, 
    833860, 
    841680, 
    843570, 
    849290, 
    851960, 
    858830, 
    862830, 
    866660, 
    874530, 
    877940, 
    880820, 
    885790, 
    889670, 
    896790, 
    903290, 
    906290, 
    909570, 
    915880
  ], 
  "text": [
    "Hi and welcome to the lab for module two", 
    "on Logistic Regression with MNIST data.", 
    "This lab is divided into two notebooks 103A,", 
    "which does the data download", 
    "and writing to a local file, and 103B", 
    "which actually builds the Logistic Regression model.", 
    "So, we'll start with 103A.", 
    "Now for both these notebooks since", 
    "the first notebook for the course", 
    "I'm going to go through each line of code,", 
    "just so we can try and understand", 
    "and everything we see and subsequent labs will go much faster.", 
    "So, this first section here is bringing in the libraries we need,", 
    "there's matplotlib, numpy, os, sys,", 
    "and then here we do a little try except", 
    "to try and find the URL live in", 
    "one of two places and that's just because there are different versions of it", 
    "and then this line right here", 
    "with % is a directive to", 
    "the Python notebook same for the matplotlib plots", 
    "that we create, make them inline in the output pane", 
    "as opposed to a floating window", 
    "that make much easier for us to manage.", 
    "OK, the first thing we're going to do is the data download", 
    "and for that we have three functions to find here. Load data,", 
    "load labels and then a try download", 
    "that calls both of them. So let's walk through and see what these are doing.", 
    "The load data starts with printing, downloading", 
    "and SRC which is the URL of he file we want to download.", 
    "Then we use this library routine called URL retrieve", 
    "to do the actual download from the SRC source file", 
    "and we put it in a local file called delete me", 
    "so we can remember to delete it if", 
    "we see it laying around later.", 
    "Once that download is finished, we print done", 
    "and then we enter this try-finally block", 
    "inside here. The first thing we do is we open the file with", 
    "gzip because it's a zip file,", 
    "we use a gzfname which is the file name that was created", 
    "when we created this delete me file", 
    "and we're going to refer to that object is gz.", 
    "The next thing we do is,", 
    "we unpack 4 bytes as gz read of 4 give us first 4 bytes of the file", 
    "and we convert that to an integer and we start with 'n'.", 
    "This is read magic number. So we're going to check", 
    "if the first element 'n'", 
    "if it's not equal to this magic number,", 
    "four zip files, then we're going to raise an exception saying", 
    "this is not available to zip file.", 
    "The Next step, we're going to read", 
    "and the number of entries that were specified up here as cimg", 
    "which is the count of images", 
    "and so we read the next 4 bytes", 
    "as a big Indian, pipe order is called big Indian in this case", 
    "into 'n' again and if they're not equal,", 
    "then something is wrong and we print out another exception error.", 
    "Otherwise, we read the next 4 bytes", 
    "into crow which is a count of  rows", 
    "and the next 4 bytes into ccol which is our count of columns.", 
    "And for this files we understand that those should both be 28.", 
    "So we say you know if either one is not 28 that we raise another exception.", 
    "If we pass all those  tests,", 
    "then we can actually read the data", 
    "and so here we have a gz read and the number of bytes to read is going to be", 
    "the number of images, times the number of rows, times of number of columns.", 
    "So we're going to get all the image data out in a very long array", 
    "and we'll store that in res, our result", 
    "and then finally we will remove the delete me", 
    "file that we created here and right now", 
    "all our member, all our data is in this res array", 
    "and the last thing we do before returning is we reshape it", 
    "such that it's a collection of", 
    "cm rows which in our case will be 60,000", 
    "and then times an array which is 28 by 28.", 
    "So, that was for the loading the data. Now, let's look at loading the labels,", 
    "going to have a similar pattern", 
    "will see a downloading message.", 
    "Here's the URL retrieved to download the source file again,", 
    "Again we're using it delete.me as the file name", 
    "And we come with gzip.open again", 
    "And we're going to unpack the first four bytes that's our magic number.", 
    "If they don't match, we raise an exception, we get the next four bytes", 
    "starting at 'n' and if that's not equal to the count of images", 
    "then something is wrong with the label file also", 
    "And now here shall we read the labels they number of bytes who going to read", 
    "is c-img which is count of images and the reason that it's exactly that is because", 
    "each label is stored in a single byte.", 
    "So we store that in our res variable,", 
    "We remove the temporary file and then we reshape this as", 
    "C as you know cimg row's by one.", 
    "So we have that array is returned", 
    "and then down here we have the try_download function,", 
    "where we give it the data source that's the URL to the data", 
    "And label source, the URL to the label", 
    "And the count of images and we just", 
    "call it to these functions we just went through.", 
    "Load data and load labels.", 
    "We store it in data and labels and then we use np.hstack", 
    "to merge them horizontally into a single array of data and labels.", 
    "So what we're going to get out of this is", 
    "something that's sixty thousand rows", 
    "and 28 by 28 is 784 plus 1 for the label should be 785.", 
    "So that should be the shape of the data that comes out of here.", 
    "So let's go down here to the next section,", 
    "here's we set up all the URLs,", 
    "So here's our images for training, our labels for training", 
    "and the number of samples is going to be 60,000.", 
    "That's the number of images and labels", 
    "and here we actually call the try_download to download them,", 
    "and we store that in train and then, we do the same thing for the test images", 
    "and labels and the number of those is going to be 10,000", 
    "and we download those into tests.", 
    "So I'm actually going to haven't run this yet", 
    "So I'm going to hit Ctrl+Enter on the first code block", 
    "and those are all functions so we don't see an output.", 
    "Now I'm also going to run this Ctrl+Enter", 
    "and we can see the output starting down here.", 
    "It's downloading the training images,", 
    "training labels and there they are, All done.", 
    "If we wanted to test the shape of these we can just insert", 
    "little cell here and say mp.shape, so let's say train", 
    "and I'm going to predict that's going to be well here. That's right,", 
    "60,000 by 785 and if we do the test", 
    "it should be 10,000 by 785 there we go.", 
    "All right! so that's what we expect.", 
    "Here's a little bit of code to visualize one of the digits.", 
    "So we're going to pick at random here sample 5,001,", 
    "We going to use matplotlibs imshow", 
    "to plot the data as an image", 
    "we'll turn off our axis and here's our sample number", 
    "coming from our training data everything but the last byte", 
    "because that last byte is our label and we reshape it to 28 by 28", 
    "Which is what I am show wants", 
    "and we're going to use a gray scale mapping", 
    "and then we'll also have a little print statement saying", 
    "what the label is using the minus 1 to get the byte at the end.", 
    "So let's run that and there we go!", 
    "So it looks like a 3 and the label for it is 3.", 
    "So that's a good sanity check. Now that we've got the data", 
    "in memory we want to write it to a local disk file", 
    "and we also want to use a particular format that CNTK prefers", 
    "which is CTF, there CNTK a text format", 
    "and what that looks like is", 
    "essentially if you can see here there's", 
    "a vertical bar labels and then the label", 
    "data followed by vertical bar features", 
    "in the feature data and so you'll see", 
    "that for each line in the text file that", 
    "we're going to create. So let's walk", 
    "through what this code does, how it does it.", 
    "first of all let's review one hot encoding.", 
    "So we're going to, right now our labels are stored in a single byte", 
    "and we want to expand those to a one hot label. So in this case", 
    "0 1 2 3, if our label is 3 we'd want to output a 1 hot label that looks like this.", 
    "So let's see how that's done in the code here, we call the save text", 
    "we give it a file name and the array of the data.", 
    "We get to extract the directory name", 
    "from the file name and make sure that it exists if it doesn't exist we create it", 
    "and if we don't already have the file and we go through this code otherwise", 
    "we can just save file already exists.", 
    "So here we say, saving the name of the file we open the file name", 
    "'w' says opening it with write and we store the file object in F", 
    "and then here is kind of a tricky part. So we're calling this NPI which", 
    "makes a diagonal matrix with diagonal ones,", 
    "I'll show you how this works let's just", 
    "understand this a little better. Let's insert a cell at the bottom that we can", 
    "play around with.", 
    "So if I just copy and paste this part of it- bring it down here, there we go", 
    "and if I run that we'll see what we get is", 
    "a 10 by 10 matrix with ones in the diagonal", 
    "and if you think about it each row here", 
    "is a potential one hot label this would", 
    "be for 0, this would be for 1, this will be for 2 & 3 & 4 and so on.", 
    "So all we have to do is use our byte label to index into this array", 
    "and take the corresponding row values there and that will be our 1 hot label.", 
    "So we store that in labels", 
    "and then we go through every row in our date array,", 
    "We convert the road to a string and then we take this labels", 
    "array which is down here this is our big 10 by 10 matrix.", 
    "We index it by row of minus 1 and the minus 1 is the last entry in that row", 
    "which is our label byte", 
    "and so this will give us one of these arrays", 
    "for one hot label and we'll store that in label_str", 
    "and then we'll take our row value up to - 1 and we'll store that in feature_str", 
    "and then we actually do the write to the F file which is our text file", 
    "that we're saving to and we'll put the vertical var labels", 
    "and then we'll call for an entry from our list here", 
    "which will be our label_str", 
    "and then we'll do vertical var features and call for an entry", 
    "for features. So let's go ahead and run this and see what it looks like", 
    "actually that's the definition", 
    "of the function we have to come down here", 
    "to see it run. so we're going to do some more stuff with paths", 
    "we're just trying to figure out here by doing these path joins, it joins", 
    "all these path parts together in one path and so we're looking for the", 
    "MNIST could be one of two places.", 
    "We have examples and tutorials in cntk, so we're first checking to see if it's in", 
    "the examples and if it's not then we look inside the tutorials directory.", 
    "Once we have our data", 
    "we actually save the text to that directory using", 
    "the directing file name specified here from the data train", 
    "and likewise we join the directory with this file name for the test", 
    "cntk. Yeah! Train a test and then I take train test data and then it says", 
    "done. So let's run this", 
    "and it happens very quickly and now that it that's done let's go and check", 
    "and see what our output file looks like this is our directory", 
    "we wrote it too. So if we look here we can see the first line", 
    "starts with the vertical var labels and then we have a one hot encoding", 
    "looks like 0 1 2 3 4 5 this is the digit", 
    "for 5. Then here's our features and we should have 784 values", 
    "till we get to the next line with this next label says", 
    "and that represents our image.", 
    "And then it continues on with the next line and new set of encoding's.", 
    "And a new set of values for the image and so on and so on.", 
    "For in this case this is the trainees that'd be for all 60,000 image label pairs.", 
    "Okay! that completes this lab, I", 
    "encourage you to go through the lab yourself", 
    "try and poke around make sure you understand what's going on", 
    "and you can also try some of the suggested exercises at the end."
  ]
}