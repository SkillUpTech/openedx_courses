{
  "start": [
    530, 
    3040, 
    7060, 
    11080, 
    13110, 
    15740, 
    20070, 
    22790, 
    25740, 
    29220, 
    31940, 
    33820, 
    36745, 
    39449, 
    43779, 
    48377, 
    50824, 
    54610, 
    57990, 
    60980, 
    63697, 
    66748, 
    69910, 
    73750, 
    78930, 
    80950, 
    85240, 
    89893, 
    94843, 
    99595, 
    104149, 
    108616, 
    112621, 
    116628, 
    120470, 
    123947, 
    127773, 
    133129, 
    138950, 
    141960, 
    146460, 
    149500, 
    154880, 
    158600, 
    160550, 
    163060, 
    166270, 
    172590, 
    178270, 
    182380, 
    185800, 
    190340, 
    194300, 
    198560, 
    204190, 
    207340, 
    210200, 
    215800, 
    219360, 
    221750, 
    225160, 
    230240, 
    240206, 
    244866, 
    249806, 
    254580, 
    259640, 
    263130, 
    266240, 
    268820, 
    272000, 
    275350, 
    279430, 
    283350, 
    285750, 
    286950, 
    292390, 
    297298, 
    300681, 
    305168, 
    308106, 
    316650, 
    319670, 
    323490, 
    327394, 
    331920, 
    334980, 
    337191, 
    340330, 
    344600, 
    348030, 
    353120, 
    356130, 
    360390, 
    364256, 
    365660, 
    369150, 
    372560, 
    379510, 
    384380, 
    390450, 
    395163, 
    398360, 
    400460, 
    406907, 
    410750
  ], 
  "end": [
    3040, 
    7060, 
    11080, 
    13110, 
    15740, 
    20070, 
    22790, 
    25740, 
    29220, 
    31940, 
    33820, 
    36745, 
    39449, 
    43779, 
    48377, 
    50824, 
    54610, 
    57990, 
    60980, 
    61637, 
    65290, 
    69910, 
    73750, 
    78930, 
    80950, 
    85240, 
    89893, 
    94843, 
    99595, 
    104149, 
    108616, 
    112621, 
    116628, 
    120470, 
    123947, 
    127773, 
    133129, 
    138950, 
    141960, 
    146460, 
    149500, 
    152680, 
    158600, 
    160550, 
    163060, 
    166270, 
    168870, 
    177020, 
    182380, 
    185800, 
    190340, 
    194300, 
    198560, 
    201870, 
    207340, 
    210200, 
    212780, 
    219360, 
    221750, 
    225160, 
    229020, 
    240206, 
    244866, 
    249806, 
    254580, 
    259640, 
    261380, 
    266240, 
    267730, 
    272000, 
    275350, 
    279430, 
    282230, 
    285750, 
    286950, 
    291080, 
    297298, 
    300681, 
    305168, 
    308106, 
    312850, 
    319670, 
    323490, 
    327394, 
    330890, 
    334980, 
    337191, 
    340330, 
    344600, 
    348030, 
    353120, 
    356130, 
    358220, 
    364256, 
    365660, 
    369150, 
    372560, 
    377599, 
    384380, 
    390450, 
    392300, 
    398360, 
    400460, 
    406907, 
    410750, 
    413450
  ], 
  "text": [
    "Welcome to the tutorial on convolutional network.", 
    "We'll continue to work with our Mnest high data set and get you", 
    "familiar with how to build model using convolutional network.", 
    "You have gone to the videos I'm sure.", 
    "You have understood the concepts behind it.", 
    "We'll quickly recapitulate some of those concepts in the form of", 
    "code and you should be able to relate to that.", 
    "And then build your own models on top of data that you", 
    "might have, using these basic networks.", 
    "And then you can go and graduate to the next level,", 
    "where you build really, really deep networks.", 
    "Because convolutional networks can be very,", 
    "very challenging because of their depth.", 
    "And as you have larger depth, you can run into problems like", 
    "we have seen in the places where you have vanishing gradients.", 
    "If you are not familiar with that terminology,", 
    "you will find it in the next module which is with LSTMs.", 
    "But in this case, we will build a reasonably small model, yet", 
    "cover all the concepts that has been taught in the video", 
    "lectures.", 
    "So let's see what we have here.", 
    "The convolutional network, as you all know, it's feed forward", 
    "artificial neural network with learnable weights and biases,", 
    "very similar to what we have seen in MLP networks before.", 
    "But we'll see how the weights and", 
    "biases are learned here and incorporated into the modeling.", 
    "I won't read through the text here but I encourage you to", 
    "quickly go through it and have a recap of what convolutional", 
    "networks are for and how are the different terminologies", 
    "associated with these networks gonna be interplaying", 
    "with the code that is gonna be introduced to you here.", 
    "One thing I would do suggest is that you revise some of these", 
    "deeper networks like the AlexNet, the VGG, Inception,", 
    "ResNet at the end of the tutorial maybe, because by then", 
    "you'll be familiar with the modeling concepts.", 
    "And then relate back to these networks and", 
    "see how you can build models, these rather deep AlexNet,", 
    "VGGs, ResNet which is 152 layers deep on your own.", 
    "If you want to fleet forward a bit,", 
    "you can go look into the next set of tutorials which", 
    "you see in tk202 in the GitHub repository to get a sense", 
    "how those networks might look like in form of code.", 
    "So this is the same problem we have with the goal of", 
    "detecting the digits.", 
    "I will train the classifier only this time.", 
    "The classifier will be based on convolutional", 
    "elements that define a convolutional network.", 
    "These are some of the imports, then we select the device.", 
    "And I wanna just quickly recap here is that in the previous", 
    "tutorial so far we have had this image.", 
    "And we have scanned it in raster fashion and", 
    "flattened it into 784 pixel.", 
    "And by doing so we lost all the spatial relationships", 
    "that exist between and its neighboring pixels.", 
    "And we will see how we can bring it back.", 
    "How we can bring these spatial neighborhoods", 
    "back into the play using convolutional networks.", 
    "Now even though our dataset is grayscale,", 
    "which means that they're single channel.", 
    "A lot of the convolution networks use natural scene", 
    "images which are multi channel, which is red, green and blue.", 
    "So, Even though our", 
    "dataset is gray scale as seen here what we have, what we find", 
    "in real world is natural scene images have three channels which", 
    "is red, green and blue and these can be specified as tuples.", 
    "The first number of the tuple is gonna be the number of channels,", 
    "then image width and image height.", 
    "By doing this, we preserve the spatial relationship between", 
    "the pixels, okay.", 
    "Now if you had a volumetric scan, that instead of a flat,", 
    "2D image, you had a 3D scan.", 
    "In which case, this data would be, number of channels would", 
    "remain to be three because of the three colors.", 
    "You can have volume width, volume height and", 
    "volume depth in this case.", 
    "So it becomes tuple with four values.", 
    "By doing this, CNTK enables you to specify any arbitrary", 
    "image with higher dimensional space.", 
    "So for instance, if your dataset had 15 colors, 16 colors,", 
    "which can happen with satellite imagery,", 
    "then this number 3 would become 16, 15, whatever it might be.", 
    "So here, we specify back to them this data set.", 
    "We are specifying the input dimension of the model to be", 
    "(1,28,28), 1 for the grayscale channel and", 
    "then 28 and 28 for the image width and height.", 
    "And then our dataset, though we have red,", 
    "is flattened in raster order.", 
    "So the input dimension here is 28 times 28.", 
    "By specifying this input_dim_model, you'll see that", 
    "when this flattened data that we have been using gets read in,", 
    "it will be put back into the two-dimensional", 
    "shape which preserves the spatial relationships", 
    "between the pixels that we have been talking about.", 
    "You're quite familiar by now with the one-hot encoding of", 
    "the labeled data.", 
    "In this case, again, this digit 3, so the 4th index,", 
    "which corresponds to digit 3 is turned on.", 
    "This is refered to as the one-hot encoded label.", 
    "Here we are gonna use the same CTFDeserializer in this course", 
    "and we will sample data using the create_reader function for", 
    "training testing purposes.", 
    "This is the place where we read the data in.", 
    "Feel free to go and", 
    "look into this Train-28x28_cntk_text.txt", 
    "file to see what the raw data looks like if you want to", 
    "convince yourself that indeed the right data is being read in."
  ]
}