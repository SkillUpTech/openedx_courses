{
  "start": [
    120, 
    5210, 
    8880, 
    12509, 
    14700, 
    18539, 
    22710, 
    25619, 
    29189, 
    32850, 
    36510, 
    39090, 
    41750, 
    45149, 
    48690, 
    52320, 
    56489, 
    62480, 
    65040, 
    70650, 
    73409, 
    77970, 
    83369, 
    87360, 
    88770, 
    92040, 
    94439, 
    98970, 
    100860, 
    104369, 
    107850, 
    111240, 
    113560, 
    115329, 
    119770, 
    123990, 
    129340, 
    133170, 
    136900, 
    139620, 
    142989, 
    145300, 
    147940, 
    149950, 
    154290, 
    159030, 
    164170, 
    167260, 
    171330, 
    175860, 
    178420, 
    180550, 
    183250, 
    186850, 
    191170, 
    193630, 
    199270, 
    202450, 
    205510, 
    207760, 
    211960, 
    215440, 
    217180, 
    218970, 
    221470, 
    224410, 
    227560, 
    231280, 
    234700, 
    239230, 
    241540, 
    245230, 
    248500, 
    250239, 
    252790, 
    256510, 
    258310, 
    261339, 
    263500, 
    265960, 
    269460, 
    272410, 
    275620, 
    278020
  ], 
  "end": [
    5210, 
    8880, 
    12509, 
    14700, 
    18539, 
    22710, 
    25619, 
    29189, 
    32850, 
    36510, 
    39090, 
    41750, 
    45149, 
    48690, 
    52320, 
    56489, 
    62300, 
    65040, 
    70650, 
    73409, 
    77970, 
    83369, 
    87360, 
    88770, 
    92040, 
    94439, 
    98970, 
    100860, 
    104369, 
    107850, 
    111240, 
    113560, 
    115329, 
    119770, 
    123990, 
    129340, 
    133170, 
    136900, 
    139620, 
    142989, 
    145300, 
    147940, 
    149950, 
    154230, 
    159030, 
    164170, 
    167260, 
    171330, 
    175860, 
    178420, 
    180550, 
    183250, 
    186850, 
    191170, 
    193630, 
    199270, 
    202450, 
    205510, 
    207760, 
    211960, 
    215440, 
    217180, 
    218970, 
    221470, 
    224410, 
    227560, 
    231280, 
    234700, 
    239230, 
    241540, 
    245230, 
    248500, 
    250239, 
    252790, 
    256510, 
    258310, 
    261339, 
    263500, 
    265960, 
    269460, 
    272410, 
    275620, 
    278020, 
    0
  ], 
  "text": [
    "we have all the components to train our", 
    "multi-layer perceptron<font color=\"#CCCCCC\"> Network we are</font>", 
    "<font color=\"#E5E5E5\">going to use the same</font><font color=\"#CCCCCC\"> trained validate</font>", 
    "test<font color=\"#CCCCCC\"> click workflow that</font><font color=\"#E5E5E5\"> you</font><font color=\"#CCCCCC\"> have seen</font>", 
    "<font color=\"#CCCCCC\">before</font><font color=\"#E5E5E5\"> the only difference here is the</font>", 
    "model<font color=\"#E5E5E5\"> itself in the previous module the</font>", 
    "model was logistic regression here it's", 
    "a multi-layer perceptron model so<font color=\"#E5E5E5\"> let's</font>", 
    "see the<font color=\"#CCCCCC\"> Train workflow remains exactly</font>", 
    "<font color=\"#CCCCCC\">the same except we are going to</font><font color=\"#E5E5E5\"> replace</font>", 
    "this<font color=\"#CCCCCC\"> part with the multi-layer</font>", 
    "perceptron model<font color=\"#E5E5E5\"> so I won't spend</font><font color=\"#CCCCCC\"> time</font>", 
    "explaining the loss function how it", 
    "evolves<font color=\"#CCCCCC\"> over the iterations</font><font color=\"#E5E5E5\"> suffice to</font>", 
    "say<font color=\"#CCCCCC\"> that during</font><font color=\"#E5E5E5\"> this stage we are</font>", 
    "finding new sets of parameters<font color=\"#E5E5E5\"> which</font>", 
    "yield lower<font color=\"#E5E5E5\"> and lower loss value</font>", 
    "subsequently<font color=\"#E5E5E5\"> in the validation workflow</font>", 
    "we select the final<font color=\"#E5E5E5\"> model based on a</font>", 
    "different data set<font color=\"#E5E5E5\"> called</font><font color=\"#CCCCCC\"> the validation</font>", 
    "<font color=\"#CCCCCC\">data</font><font color=\"#E5E5E5\"> set such</font><font color=\"#CCCCCC\"> that</font><font color=\"#E5E5E5\"> the loss is the least</font>", 
    "on the validation<font color=\"#E5E5E5\"> data set so let's</font>", 
    "start with the same data base<font color=\"#CCCCCC\"> the Emnes</font>", 
    "database here we are you going<font color=\"#CCCCCC\"> to use</font>", 
    "the<font color=\"#E5E5E5\"> training data set again pretty</font><font color=\"#CCCCCC\"> much</font>", 
    "nothing changes<font color=\"#CCCCCC\"> here we sample a</font><font color=\"#E5E5E5\"> mini</font>", 
    "batch of size 128 these are the number", 
    "<font color=\"#E5E5E5\">of images that we are drawing</font><font color=\"#CCCCCC\"> from this</font>", 
    "<font color=\"#E5E5E5\">M nice database and the corresponding</font>", 
    "labels which are<font color=\"#E5E5E5\"> not encoded now this is</font>", 
    "where<font color=\"#E5E5E5\"> things are different right the</font>", 
    "model here", 
    "is the multi-layer perceptron model that", 
    "we have seen<font color=\"#E5E5E5\"> during the lectures the</font>", 
    "first dense layer<font color=\"#E5E5E5\"> produces 400 outputs</font>", 
    "the second one has 200 output and the", 
    "final one emits an array<font color=\"#CCCCCC\"> of</font><font color=\"#E5E5E5\"> 10 numbers</font>", 
    "<font color=\"#E5E5E5\">representing the</font><font color=\"#CCCCCC\"> ten</font><font color=\"#E5E5E5\"> digits that we are</font>", 
    "<font color=\"#E5E5E5\">trying to classify we are using</font>", 
    "activation function value<font color=\"#E5E5E5\"> here</font><font color=\"#CCCCCC\"> in the</font>", 
    "hidden<font color=\"#E5E5E5\"> layers since we are going to use</font>", 
    "<font color=\"#E5E5E5\">softmax we do not use an activation</font>", 
    "function<font color=\"#E5E5E5\"> we just have it</font><font color=\"#CCCCCC\"> as a</font>", 
    "<font color=\"#CCCCCC\">pass-through in the final output layer</font>", 
    "so there<font color=\"#E5E5E5\"> are six sets of</font><font color=\"#CCCCCC\"> parameters</font>", 
    "<font color=\"#E5E5E5\">three weights</font><font color=\"#CCCCCC\"> and three biases our loss</font>", 
    "function is<font color=\"#E5E5E5\"> cross-entropy with softmax</font>", 
    "<font color=\"#E5E5E5\">which takes the</font><font color=\"#CCCCCC\"> output of the model</font><font color=\"#E5E5E5\"> and</font>", 
    "<font color=\"#E5E5E5\">labels from our training set</font>", 
    "optionally<font color=\"#E5E5E5\"> we also use the</font>", 
    "classification error function to<font color=\"#E5E5E5\"> figure</font>", 
    "out how well our<font color=\"#E5E5E5\"> classifier is doing</font>", 
    "against<font color=\"#E5E5E5\"> the ground truth or the labeled</font>", 
    "set and then using the trainer object", 
    "<font color=\"#E5E5E5\">which takes the model the</font><font color=\"#CCCCCC\"> loss the error</font>", 
    "and learner<font color=\"#E5E5E5\"> functions we train our model</font>", 
    "<font color=\"#E5E5E5\">by repeatedly calling trainer dot</font><font color=\"#CCCCCC\"> train</font>", 
    "underscore mini-batch with the data and", 
    "<font color=\"#E5E5E5\">the labels provided to the function as</font>", 
    "an input the learners can be any<font color=\"#E5E5E5\"> one of</font>", 
    "them such as<font color=\"#E5E5E5\"> SGD</font><font color=\"#CCCCCC\"> or a grad etc that we</font>", 
    "have introduced to you<font color=\"#CCCCCC\"> in</font><font color=\"#E5E5E5\"> the last</font>", 
    "<font color=\"#E5E5E5\">lecture</font>", 
    "following the selection of the final", 
    "<font color=\"#E5E5E5\">model we want to test what its</font>", 
    "performance is going to<font color=\"#CCCCCC\"> be</font><font color=\"#E5E5E5\"> on data set</font>", 
    "that<font color=\"#E5E5E5\"> hasn't been</font><font color=\"#CCCCCC\"> used for training</font><font color=\"#E5E5E5\"> so</font>", 
    "<font color=\"#E5E5E5\">using the final model we sample data</font>", 
    "sets from<font color=\"#E5E5E5\"> the test database and using</font>", 
    "the final model<font color=\"#E5E5E5\"> we generate predictions</font>", 
    "<font color=\"#CCCCCC\">and calculate the error let's see how</font>", 
    "the test workflow<font color=\"#CCCCCC\"> looks out here we do</font>", 
    "not<font color=\"#CCCCCC\"> want to sample from</font><font color=\"#E5E5E5\"> the training</font>", 
    "<font color=\"#E5E5E5\">data set</font><font color=\"#CCCCCC\"> we sample from the test data</font>", 
    "set we sample the input<font color=\"#E5E5E5\"> data or the</font>", 
    "features in this case what we call and", 
    "the corresponding labels note in<font color=\"#E5E5E5\"> this</font>", 
    "<font color=\"#CCCCCC\">case the model</font><font color=\"#E5E5E5\"> is frozen</font>", 
    "that means the weights and<font color=\"#E5E5E5\"> the bias</font>", 
    "values are fixed<font color=\"#CCCCCC\"> they are not changing</font>", 
    "<font color=\"#E5E5E5\">we call trainer dot test underscore</font>", 
    "mini-batch<font color=\"#E5E5E5\"> repeatedly and evaluate the</font>", 
    "average error<font color=\"#E5E5E5\"> that this model would</font>", 
    "<font color=\"#E5E5E5\">produce</font>"
  ]
}