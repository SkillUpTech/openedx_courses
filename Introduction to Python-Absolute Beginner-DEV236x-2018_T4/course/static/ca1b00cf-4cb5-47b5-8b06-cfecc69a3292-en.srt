0
00:00:00,730 --> 00:00:04,750
Now that we have preprocessed data and

1
00:00:04,750 --> 00:00:10,740
we know how to deal with recurrence, how to incorporate

2
00:00:10,740 --> 00:00:14,660
long recurrent architectures using LSTMs.

3
00:00:15,770 --> 00:00:19,670
And we also know how to control over-fitting using dropouts,

4
00:00:19,670 --> 00:00:20,930
in this case.

5
00:00:20,930 --> 00:00:24,710
Let's put together a model.

6
00:00:24,710 --> 00:00:30,670
So the input, I repeat, are 14 data points that

7
00:00:30,670 --> 00:00:34,980
we preprocessed, represented by this pink window here.

8
00:00:34,980 --> 00:00:38,497
And the output is this single value of

9
00:00:38,497 --> 00:00:41,679
the solar panel on a future date.

10
00:00:44,640 --> 00:00:46,170
Here's our network.

11
00:00:46,170 --> 00:00:50,930
If you notice, we've added a dropout layer right here.

12
00:00:52,660 --> 00:00:54,375
This is to control overfitting.

13
00:00:56,750 --> 00:00:59,200
And how does it translate it into code?

14
00:00:59,200 --> 00:01:00,180
It's very simple.

15
00:01:00,180 --> 00:01:05,080
Previously we had recurrent layers of the LSTM blocks here.

16
00:01:06,430 --> 00:01:12,587
We had pulled the last element from the recurrent

17
00:01:12,587 --> 00:01:17,880
sequence here, using sequence.last.

18
00:01:17,880 --> 00:01:24,507
Then we added a Dropout with a probability of 0.2.

19
00:01:24,507 --> 00:01:26,260
This is a parameter you can play around.

20
00:01:27,920 --> 00:01:32,428
And then, since we're emitting just a single value,

21
00:01:32,428 --> 00:01:36,062
we use a dense projection with a value of 1.

22
00:01:36,062 --> 00:01:39,025
LetÂ´s see how the train test and

23
00:01:39,025 --> 00:01:45,180
predict work flow looks like for this particular model.

24
00:01:45,180 --> 00:01:50,060
Now let's see how we can put together the pieces that we

25
00:01:50,060 --> 00:01:54,740
have learned in this module into the train validation workflow.

26
00:01:56,530 --> 00:01:58,130
What are the things that are different here?

27
00:02:00,010 --> 00:02:01,200
The first thing is

28
00:02:02,420 --> 00:02:05,090
the model here is a recurrence based model.

29
00:02:07,880 --> 00:02:13,470
Compared to the MS data we are dealing with sequences here.

30
00:02:15,210 --> 00:02:19,580
We'll see how we factor that in into our modeling work flow.

31
00:02:21,370 --> 00:02:25,224
The overall schema for training, and validation, and

32
00:02:25,224 --> 00:02:27,849
model selection, remains the same.

33
00:02:30,714 --> 00:02:34,100
So we take the solar panel output data from

34
00:02:34,100 --> 00:02:35,653
the training set.

35
00:02:37,762 --> 00:02:41,819
We sample 96 sequences.

36
00:02:43,470 --> 00:02:45,848
This will be called the mini-batch.

37
00:02:47,454 --> 00:02:50,190
Here there are 96 sequences.

38
00:02:50,190 --> 00:02:55,867
And each sequence here represents a value, a numerical

39
00:02:55,867 --> 00:03:01,195
value of the recorded current from the solar panel.

40
00:03:03,816 --> 00:03:08,499
And the corresponding label in this case is the known output of

41
00:03:08,499 --> 00:03:09,859
the solar panel.

42
00:03:13,096 --> 00:03:21,153
Notice that the length of the sequence is changing.

43
00:03:21,153 --> 00:03:26,169
And this can happen because the solar panel may not be

44
00:03:26,169 --> 00:03:31,983
producing any electricity during certain parts of the day,

45
00:03:31,983 --> 00:03:36,087
or some air conditions lead it to not report

46
00:03:36,087 --> 00:03:39,965
a particular time point during the day.

47
00:03:39,965 --> 00:03:44,899
And the length of the sequences keep changing in the case of

48
00:03:44,899 --> 00:03:47,630
time series modeling.

49
00:03:47,630 --> 00:03:50,446
And one need to be aware of it.

50
00:03:50,446 --> 00:03:55,610
The data is then processed by the model,

51
00:03:56,960 --> 00:04:00,180
you can see the model has the recurrence units.

52
00:04:01,720 --> 00:04:05,790
And we pick up the last units output and

53
00:04:05,790 --> 00:04:08,320
pass it to a dropout there.

54
00:04:08,320 --> 00:04:13,730
And then emit the predicted value of the solar panel output.

55
00:04:15,520 --> 00:04:20,500
In this case, unlike the previous exercises,

56
00:04:20,500 --> 00:04:22,780
we are predicting a real number.

57
00:04:24,710 --> 00:04:30,556
Hence, we want to compute the difference

58
00:04:30,556 --> 00:04:35,180
between the models prediction, say we call it

59
00:04:35,180 --> 00:04:39,080
the Y* which is an output of the z in terms of x.

60
00:04:40,420 --> 00:04:44,240
And the known output from the solar panel, Y,

61
00:04:44,240 --> 00:04:47,890
we want to minimize the difference between these two.

62
00:04:49,570 --> 00:04:52,280
And we use squared_error for that purpose.

63
00:04:53,450 --> 00:04:54,840
And that is our loss function.

64
00:04:57,650 --> 00:05:01,919
In this case, we also use the same function for

65
00:05:01,919 --> 00:05:06,296
measuring the error between our prediction and

66
00:05:06,296 --> 00:05:11,448
what we observed as the known output of the solar panel.

67
00:05:14,280 --> 00:05:18,331
So now we have the model, loss and error functions and

68
00:05:18,331 --> 00:05:20,230
a choice of the learner.

69
00:05:22,000 --> 00:05:26,570
This trainer object can now take different instances

70
00:05:26,570 --> 00:05:31,510
of the minibatch samples and

71
00:05:31,510 --> 00:05:36,200
come up with the optimal set of parameters for this model.

72
00:05:38,270 --> 00:05:41,610
Again, you have a range of learners to choose from.

73
00:05:42,800 --> 00:05:47,080
And one should experiment with the different learners, or

74
00:05:47,080 --> 00:05:48,870
in this case I'm calling it solvers.

75
00:05:50,520 --> 00:05:54,281
The test workflow is same as before again,

76
00:05:54,281 --> 00:05:58,568
you have a model that you've already selected.

77
00:06:01,127 --> 00:06:05,743
Now you're going to sample different data points from

78
00:06:05,743 --> 00:06:10,461
the test database and measure the average error between

79
00:06:10,461 --> 00:06:14,290
the predicted value and the observed value.

80
00:06:16,390 --> 00:06:18,900
You start with the test database.

81
00:06:18,900 --> 00:06:23,620
You sample the different readings for

82
00:06:23,620 --> 00:06:29,390
a given day with their corresponding output.

83
00:06:29,390 --> 00:06:31,520
You use the trained model here.

84
00:06:33,000 --> 00:06:37,990
And determine the error between the predicted value

85
00:06:37,990 --> 00:06:42,273
out of the model using this minibatch

86
00:06:42,273 --> 00:06:45,610
sample data and their corresponding labels.

87
00:06:46,960 --> 00:06:50,310
So this function would return the squared error between

88
00:06:50,310 --> 00:06:53,320
the observed and the predicted output from the solar panel.

89
00:06:54,425 --> 00:06:59,280
Note one thing though, is in the model you will not see

90
00:06:59,280 --> 00:07:02,670
any different logic to accommodate the different

91
00:07:02,670 --> 00:07:05,610
lengths in the input sample, these varying lengths.

92
00:07:07,600 --> 00:07:13,650
This is automatically taken care of behind the scenes for you.

93
00:07:13,650 --> 00:07:17,210
Where the length of the recurrence units can be

94
00:07:17,210 --> 00:07:20,470
automatically adjusted based on the length of the sequences.

95
00:07:21,900 --> 00:07:26,790
As one gets into more complex networks

96
00:07:26,790 --> 00:07:30,430
with different kinds of sequence information,

97
00:07:30,430 --> 00:07:35,940
that level of abstraction really helps focus the developers or

98
00:07:35,940 --> 00:07:42,090
the scientists attention on how to architect the model itself.

99
00:07:44,550 --> 00:07:48,750
This is a huge advantage for folks dealing with practical

100
00:07:48,750 --> 00:07:51,420
deep learning problems that they want to solve.

101
00:07:53,190 --> 00:07:56,190
Now coming back to the solar panel data,

102
00:07:56,190 --> 00:07:58,120
once you have the model train.

103
00:08:00,370 --> 00:08:04,890
Any arbitrary day you get a set of readings from the solar

104
00:08:04,890 --> 00:08:09,380
panel, the model will be able to predict the output

105
00:08:09,380 --> 00:08:14,100
from the set of input points for that particular day.

106
00:08:14,100 --> 00:08:17,371
And this can be easily, you can imagine,

107
00:08:17,371 --> 00:08:21,951
be part of a IoT device at your home where it can show how much

108
00:08:21,951 --> 00:08:25,597
electricity you can expect to be generated for

109
00:08:25,597 --> 00:08:30,085
any given day ahead of time based on a few readings that you

110
00:08:30,085 --> 00:08:33,669
may have collected for that particular day.

111
00:08:33,669 --> 00:08:37,322
Or if you change the model slightly you can use any other

112
00:08:37,322 --> 00:08:41,217
recurrences from past days to be able to get a very reliable

113
00:08:41,217 --> 00:08:44,570
estimate of what the solar panel output might be.

