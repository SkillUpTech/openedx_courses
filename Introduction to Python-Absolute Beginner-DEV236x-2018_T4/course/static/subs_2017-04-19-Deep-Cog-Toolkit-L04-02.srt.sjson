{
  "start": [
    880, 
    4594, 
    7210, 
    10132, 
    13595, 
    17416, 
    19256, 
    23970, 
    27050, 
    30690, 
    33450, 
    38470, 
    43186, 
    47790, 
    52394, 
    56370, 
    58748, 
    61060, 
    63320, 
    66090, 
    70800, 
    72860, 
    76700, 
    82755, 
    85755, 
    89795, 
    92765, 
    98570, 
    100930, 
    104160, 
    105197, 
    107640, 
    110822, 
    113918, 
    117630, 
    120720, 
    123880, 
    125560, 
    128670, 
    131160, 
    132900, 
    133803, 
    136717, 
    142549, 
    147400, 
    148800, 
    151040, 
    153590, 
    156880, 
    160524, 
    163583, 
    165483, 
    169440, 
    173404, 
    177382, 
    181254, 
    183580, 
    184290, 
    188210, 
    190120, 
    194281, 
    199531, 
    202120, 
    205530, 
    209470, 
    212820, 
    216780, 
    219480, 
    223264
  ], 
  "end": [
    4594, 
    7210, 
    10132, 
    13595, 
    17416, 
    19256, 
    23970, 
    27050, 
    30690, 
    33450, 
    38470, 
    43186, 
    47790, 
    52394, 
    56370, 
    58748, 
    61060, 
    63320, 
    66090, 
    68940, 
    71650, 
    76700, 
    82755, 
    85755, 
    89795, 
    92765, 
    96175, 
    100930, 
    104160, 
    105197, 
    107640, 
    110822, 
    113918, 
    117630, 
    120720, 
    123880, 
    125560, 
    128670, 
    131160, 
    132900, 
    133803, 
    136717, 
    142549, 
    146040, 
    148800, 
    151040, 
    153590, 
    155329, 
    160524, 
    163583, 
    165483, 
    168400, 
    173404, 
    177382, 
    181254, 
    183580, 
    184290, 
    188210, 
    190120, 
    194281, 
    199531, 
    202120, 
    205530, 
    209470, 
    212820, 
    216780, 
    219480, 
    223264, 
    226840
  ], 
  "text": [
    "Next thing to do would be to go through the model creation", 
    "process for convolutional networks.", 
    "So we've taken this input image,", 
    "in this case we are showing an RGB image.", 
    "And you know that we specify this input dimension as three", 
    "times width times height.", 
    "And in the case of MNIST data we will only have a single channel.", 
    "So in this case, let's go through this illustration which", 
    "you have already seen it during the video lectures.", 
    "In this case, we are gonna estimate this", 
    "filters which are defined by this W matrix if you might say.", 
    "And the bias values, these are single scalar values.", 
    "And you take the dot product between the weights and", 
    "the corresponding footprint, which we refer to as", 
    "the receptive field of the image location.", 
    "When the filter W is superimposed,", 
    "we are gonna learn n such filters.", 
    "So let's take a look at this animation here,", 
    "what it spells out for us.", 
    "We will take a look at it from the top.", 
    "Give it a moment.", 
    "All right, now we are scanning in raster order, the kernel is", 
    "moving from left to right and then bottom to top in this case.", 
    "And create the first output set,", 
    "which is the output of those dot product plus the bias value", 
    "added optionally passed through an activation function.", 
    "And we are gonna repeat this process for n such filters.", 
    "Let's go through this cycle again, once again.", 
    "You can see the scanning order that is happening here for", 
    "the first layer.", 
    "You repeat the process, then you go to the second layer.", 
    "You again do the same scanning, zig-zag,", 
    "through all the possible steps you have for", 
    "this particular filter sets that we are learning.", 
    "In this case, there are four shown here but with the dot,", 
    "dot, dot, you can have arbitrary number of them below.", 
    "Take a look at it, and", 
    "convince yourself the process of convolution.", 
    "The advantages of convolutions are spelled out here.", 
    "I won't get go into details.", 
    "Feel free to read through it.", 
    "But what it enables us to do is,", 
    "by doing this kind of shared weights that are learned across,", 
    "we are able to handle larger images.", 
    "In this case, say 512 by 512.", 
    "You can try larger filter sizes.", 
    "You can learn more filters.", 
    "You can go to deeper architectures.", 
    "We also are able to do something called a translation invariance,", 
    "which is the ability to recognize a feature independent", 
    "of where they appear in the image.", 
    "This can be quite important for real-world examples.", 
    "The other parameter that we often run into is strides and", 
    "pads associated with the network that we get to choose.", 
    "These are network parameters that are chosen by the person", 
    "who is building the model.", 
    "In this case,", 
    "we have seen these animations in the video lectures.", 
    "So take a close look at it.", 
    "If you see that between stride one and stride two,", 
    "the output image size, which is the teal colored output here,", 
    "you can see, are difference.", 
    "So a lot of these choices of these parameters are based on", 
    "what your output shapes for the each layer, you want it to be.", 
    "And there is a corresponding relationship with the number of", 
    "parameters, which we will shortly see how these", 
    "different type of parameters such as strides.", 
    "The filter shapes come into the picture when you are computing", 
    "the number of parameters you are going to have in your model"
  ]
}