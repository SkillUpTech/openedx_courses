{
  "start": [
    360, 
    5290, 
    10850, 
    15670, 
    21660, 
    27763, 
    32460, 
    37365, 
    42420, 
    45830, 
    46560, 
    50710, 
    56950, 
    61580, 
    66630, 
    70320, 
    73430, 
    76420, 
    77428, 
    82470, 
    88670, 
    92540, 
    96710, 
    99030, 
    104037, 
    109513, 
    113323, 
    117620, 
    118445, 
    122091, 
    126700, 
    132232, 
    136450, 
    141350, 
    144770, 
    148000, 
    152615, 
    156330, 
    157950, 
    160360, 
    163930, 
    170120, 
    175530, 
    181590, 
    186200, 
    189480, 
    196110, 
    202220, 
    204050, 
    209430, 
    212900, 
    219936, 
    227856, 
    232481, 
    237199, 
    241210, 
    244475, 
    250660, 
    255168, 
    258405, 
    263340
  ], 
  "end": [
    5290, 
    10850, 
    15670, 
    21660, 
    27763, 
    32460, 
    37365, 
    42420, 
    44760, 
    46560, 
    50710, 
    55650, 
    61580, 
    66630, 
    68040, 
    73430, 
    76420, 
    77428, 
    82470, 
    86800, 
    92540, 
    93695, 
    99030, 
    104037, 
    109513, 
    113323, 
    117620, 
    118445, 
    122091, 
    125130, 
    128930, 
    135390, 
    141350, 
    144770, 
    146860, 
    152615, 
    154750, 
    157950, 
    160360, 
    163930, 
    168360, 
    173654, 
    181590, 
    186200, 
    189480, 
    196110, 
    199560, 
    204050, 
    207220, 
    210610, 
    219936, 
    225130, 
    232481, 
    237199, 
    241210, 
    244475, 
    250660, 
    255168, 
    258405, 
    263340, 
    266570
  ], 
  "text": [
    "We have now mastered all the components that we need", 
    "to put together our application of forecasting the output", 
    "of a solar panel based on past", 
    "observations of what the panel produced.", 
    "That was over timeseries of, say, 14 data points.", 
    "We'll see how the module is made.", 
    "But before we get to that, an important component of any", 
    "machine learning as well as deep learning technologies,", 
    "is to figure out what to do with the data.", 
    "In the tutorial,", 
    "you'll see there is a lot of code that goes towards preparing", 
    "the data, and understanding the data is equally important.", 
    "In the next several slides, I'll walk you through", 
    "what the data are with respect to the IoT device.", 
    "In this case, it's a solar panel.", 
    "So the output of the solar panel are measurements", 
    "that are recorded at every 30 minutes interval.", 
    "This is our data.", 
    "Each time point, we record the solar.current,", 
    "which is the current production in Watts.", 
    "And solar.total, which is the total production for the day, so", 
    "far in Watts/hour.", 
    "This is what the data looks like.", 
    "Starting at a time in the day, two values are recorded.", 
    "At 7 AM, 6.3 units was the solar.current value,", 
    "which is the current production, and", 
    "the total output at that point was 1.7.", 
    "At 7:30,", 
    "it was similarly recorded what were the current production and", 
    "what were the total production, so on and so forth.", 
    "We are using about 3 years worth of data.", 
    "And the input data that we are using is not cleansed.", 
    "So it's very important that you build your code and", 
    "definitely budget time to cleanse errors", 
    "that might be present in your raw input data.", 
    "For instance, there could be a panel that failed to report, and", 
    "it is included with the data.", 
    "There are two ways.", 
    "One is to purge some of the data,", 
    "or, using deep learning techniques,", 
    "you can use the model to compensate for the missing data.", 
    "So here is the goal for our data pre-processing.", 
    "Compose sequence such that each training instance will be X.", 
    "Remember, this is our input, which is the solar.current from", 
    "time equals 1 to time equals 14.", 
    "This corresponds to one days worth of records from the panel.", 
    "And Y is the predicted total production for a future day.", 
    "What are the steps?", 
    "First, we read raw data into a pandas dataframe.", 
    "We normalize the data.", 
    "Group the data by day, append these columns to the dataframe,", 
    "and then generate the sequences for each day.", 
    "Some data filtering that we do is, if we have less than 8 data", 
    "points, that means between time 1 to 14, if there are more", 
    "than eight missing data points, then we skip.", 
    "We don't use it for the modeling purposes.", 
    "And if we have more than 14 data points, we simply truncate.", 
    "Now, once this sequence of X and Ys are formed, note,", 
    "we do not need the timestamps anymore.", 
    "And each pair of X and Y are self-contained instances that", 
    "are used in our training of the model."
  ]
}