{
  "start": [
    520, 
    4660, 
    9900, 
    14360, 
    16760, 
    19440, 
    22160, 
    25680, 
    28520, 
    30480, 
    34100, 
    38120, 
    44460, 
    48500, 
    50600, 
    56780, 
    59880, 
    64260, 
    65460, 
    70300, 
    72780, 
    74320, 
    78140, 
    84520, 
    87930, 
    90520, 
    92400, 
    99466, 
    103260, 
    106180, 
    109340, 
    113380, 
    115900, 
    118140
  ], 
  "end": [
    3660, 
    8960, 
    14130, 
    16660, 
    19330, 
    22000, 
    25640, 
    28120, 
    30400, 
    32980, 
    37780, 
    43660, 
    48200, 
    50200, 
    56040, 
    59160, 
    64000, 
    65400, 
    69620, 
    72560, 
    74260, 
    78060, 
    83920, 
    87520, 
    90440, 
    92320, 
    97560, 
    103066, 
    106060, 
    109120, 
    113200, 
    115700, 
    118000, 
    121980
  ], 
  "text": [
    "Now that we have put together a pretty decent", 
    "set of layered components together.", 
    "We have a Convolution based deep network.", 
    "Let's figure out how we can", 
    "put these together into a training workflow.", 
    "Much of these going to be very familiar to you.", 
    "But it will be in the context of the convolution operations", 
    "and the layered elements that", 
    "you just learnt in this module.", 
    "We will be incorporating those into the workflow.", 
    "So we start with the digit 3", 
    "from MNIST. And we will give that as an input to the", 
    "convolution model without flattening that.", 
    "So here we are going to learn", 
    "8(5x5) weight matrix + 8 biases.", 
    "Then we have a pooling layer", 
    "then we have a another convolution operation here.", 
    "And here we are learning", 
    "16(5x5)weight matrices and the corresponding 16 biases.", 
    "And then you have the another pooling layer", 
    "followed by a dense layer.", 
    "So the parameters we are going to learn here", 
    "are this layer, this layer and the dense layer. Ok!", 
    "And here is the output of the dense layer which", 
    "is same as before in the", 
    "output numbers are going to be different.", 
    "But the shape of the output is going to be vector of 10 numbers.", 
    "It will compute the error of the loss function", 
    "where we will pass the digit 3", 
    "through the model generated, it's predicted probabilities", 
    "and then compare it with the one-hot encoded label", 
    "that comes along with the training set", 
    "and we will use our friend", 
    "cross entropy to compute the loss function."
  ]
}