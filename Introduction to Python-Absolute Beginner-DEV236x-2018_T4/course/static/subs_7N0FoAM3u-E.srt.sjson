{
  "start": [
    540, 
    4370, 
    10540, 
    14390, 
    17100, 
    20090, 
    22660, 
    25270, 
    27410, 
    30180, 
    31720, 
    34770, 
    37520, 
    40263, 
    43430, 
    48950, 
    52640, 
    59010, 
    60930, 
    61880, 
    65300, 
    70050, 
    75820, 
    79270, 
    82660, 
    87710, 
    90810, 
    95550, 
    97460, 
    102950, 
    107233, 
    111090, 
    116281, 
    120763, 
    122830, 
    125960, 
    128770, 
    131600, 
    133110, 
    137140, 
    140450, 
    143600, 
    148610, 
    153540, 
    158180, 
    161180, 
    163650, 
    168400, 
    173670, 
    178210, 
    181370, 
    185350, 
    189907, 
    193627
  ], 
  "end": [
    4370, 
    8330, 
    13210, 
    17100, 
    20090, 
    22660, 
    25270, 
    26160, 
    30180, 
    31720, 
    34770, 
    35760, 
    40263, 
    43430, 
    48950, 
    50750, 
    57310, 
    60930, 
    61880, 
    65300, 
    70050, 
    75820, 
    79270, 
    82660, 
    87710, 
    90810, 
    95550, 
    96450, 
    102950, 
    107233, 
    111090, 
    113190, 
    120763, 
    122830, 
    124940, 
    127190, 
    131600, 
    133110, 
    137140, 
    140450, 
    143600, 
    148610, 
    153540, 
    158180, 
    161180, 
    163650, 
    168400, 
    173670, 
    176220, 
    181370, 
    183100, 
    189907, 
    193627, 
    198283
  ], 
  "text": [
    "You have seen how adding convolution", 
    "has helped us reduce the error rate to the MNIST data.", 
    "Let's see how we can further improve the performance.", 
    "One of the key aspect of training these", 
    "networks is to guard against overfitting because", 
    "you're dealing with a lot of parameters.", 
    "And one of the effective ways of dealing with it is", 
    "something called pooling.", 
    "So pooling is typically inserted between successive", 
    "Convolution layers.", 
    "And the goal is to reduce the number of parameters and", 
    "control overfitting.", 
    "So some of the popular pooling options,", 
    "we'll go through two of them are max pooling.", 
    "What we do here is we take a region and", 
    "find the maximum value within it.", 
    "And that becomes the output of that particular patch.", 
    "And in this case we are illustrating it with", 
    "a stride of two.", 
    "So we have a two by two region with a stride of two.", 
    "So this window is going to slide over to this part here.", 
    "And then we find the max within that region and,", 
    "as stated here, and you repeat it over the whole image.", 
    "So you can see that we're using max pooling, we are grabbing", 
    "the most salient output from that particular input.", 
    "And also at the same time reducing the number of", 
    "parameters associated by reducing the size of the output", 
    "of the max pooling layer.", 
    "You can also do average pooling, which is, you slide a window", 
    "over the different areas of the image that you have.", 
    "And then wherever you slide that, you compute the average of", 
    "it and that becomes the corresponding output.", 
    "A typical convolution network with max pooling would look like", 
    "something like this.", 
    "So, you have a convolution layer,", 
    "then you would add a pooling layer.", 
    "And you can control the size of the region", 
    "that you want to pool.", 
    "And also the strikes associated with it.", 
    "And you keep doing this for a few times.", 
    "You layer it on top of the other and", 
    "the final layer you project the output of the previous layer.", 
    "And the output dimension is kept to 10, so that we can", 
    "recognize the 10 digits that correspond to the input image.", 
    "So here is the corresponding model that you can", 
    "train as a part of your assignment.", 
    "Here you will have a convolution to the operation", 
    "corresponding to this particular block here and the parameters", 
    "have one to one correspondence to each of the blocks.", 
    "And what can you get by doing this convolution", 
    "combined with max pooling operation?", 
    "The error rate for MNIST data comes down to close to a 1%,", 
    "which is a significant jump from our LR model and", 
    "also a significant improvement over our previous models."
  ]
}