{
  "start": [
    980, 
    4490, 
    9440, 
    12530, 
    15610, 
    16880, 
    20010, 
    24110, 
    26810, 
    31499, 
    34286, 
    38340, 
    48125, 
    50670, 
    57360, 
    63760, 
    68143, 
    72732, 
    74738, 
    81150, 
    83410, 
    90236, 
    99284, 
    104073, 
    108527, 
    110594, 
    115195, 
    117338, 
    120610, 
    125310, 
    129180, 
    131920, 
    136040, 
    139580, 
    142773, 
    148620, 
    152830, 
    155130, 
    158830, 
    164880, 
    167620, 
    171650, 
    175280, 
    178500, 
    183450, 
    185710, 
    187990, 
    191920, 
    193580, 
    197530, 
    203140
  ], 
  "end": [
    4490, 
    9440, 
    12530, 
    15610, 
    16880, 
    20010, 
    24110, 
    26810, 
    31499, 
    34286, 
    38340, 
    44447, 
    49500, 
    55410, 
    62351, 
    68143, 
    69247, 
    74738, 
    78760, 
    83410, 
    87141, 
    96694, 
    104073, 
    108527, 
    110594, 
    115195, 
    117338, 
    120610, 
    125310, 
    129180, 
    131920, 
    136040, 
    139580, 
    142773, 
    145545, 
    152830, 
    153630, 
    158830, 
    163780, 
    167620, 
    171650, 
    172890, 
    178500, 
    182220, 
    185710, 
    187990, 
    191920, 
    193580, 
    195620, 
    202070, 
    206350
  ], 
  "text": [
    "Now that you have a fairly good intuition of what", 
    "recurrence means and how important history can be.", 
    "And we've introduced you to the input data", 
    "with the dimension that is different from the dimension", 
    "that you get from the history.", 
    "The input dimension of the data was n dimension.", 
    "And if you noticed the dimensions", 
    "of the history unit was m dimensional.", 
    "Let's figure out how we can take a history,", 
    "say from time t minus one,", 
    "add to it the current input at time t and", 
    "generate the new history and the corresponding output.", 
    "Here is our model.", 
    "We have the input, x(t), and the corresponding output.", 
    "And we have the history here, from t minus 1.", 
    "And we want to generate a new history based on the new input", 
    "that came in.", 
    "So what we do is first,", 
    "start with the n dimensional input at time t.", 
    "And we also bring in the history,", 
    "from the previous time step which is m-dimensional.", 
    "We put them together so now our data set is n plus m dimension.", 
    "We'll take this new input x* and", 
    "update our history for time t.", 
    "And this is gonna be, again,", 
    "m dimensional because we want to recur a cross time step.", 
    "This was m dimensional,", 
    "the intermedia data point is n plus m.", 
    "We want to project it back to an m dimensional space.", 
    "You already know how to do it from past experiences and", 
    "lectures, and", 
    "our dense layer comes to help where we take the input.", 
    "So the input of the dense layer is n plus m vector.", 
    "And the output is m dimensional output, and", 
    "we use an activation of ten each here.", 
    "And by using that we are able to project the input into a new", 
    "history.", 
    "So once we have the output which is m dimensional output", 
    "you can also think of it as our standard matrix multiplication.", 
    "Here, with the bias added.", 
    "And additionally, you route it to a ten H non-linearity", 
    "to generate the new history.", 
    "If you want to emit an output here, YT,", 
    "you can project it into C number of classes, the output of this.", 
    "I said to a softmax.", 
    "If you do not want to see classes,", 
    "you want to just project say, the output of the solar panel", 
    "then you do not need to use softmax.", 
    "You will see later on, we will use something else.", 
    "Because the output of the solar panel is a real number and", 
    "this is gonna be your basic recurrent unit."
  ]
}