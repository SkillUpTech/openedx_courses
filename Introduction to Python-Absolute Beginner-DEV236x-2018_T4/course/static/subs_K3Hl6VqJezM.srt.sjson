{
  "start": [
    1400, 
    3200, 
    5520, 
    8500, 
    12760, 
    17800, 
    23080, 
    27440, 
    33780, 
    36840, 
    39920, 
    43700, 
    47160, 
    51780, 
    53860, 
    59260, 
    65380, 
    72400, 
    74780, 
    77540, 
    79960, 
    84440, 
    87620, 
    90940, 
    93580, 
    96500, 
    99720, 
    109320, 
    110940, 
    114480, 
    118460, 
    124380, 
    127500, 
    131980, 
    136460, 
    138640, 
    141020, 
    146160, 
    150020, 
    155340, 
    160240, 
    161920, 
    168740, 
    170380, 
    174640, 
    178570, 
    185040, 
    193008, 
    196864, 
    199456, 
    206736, 
    210240, 
    216192, 
    221280, 
    227552, 
    232512, 
    236240, 
    240304, 
    244190, 
    251760, 
    256640, 
    260944, 
    267328, 
    275632, 
    282400, 
    285488, 
    287024, 
    292304, 
    295840, 
    299952, 
    305632, 
    312976, 
    322528, 
    324624, 
    330064, 
    333760, 
    338640, 
    343152, 
    347216, 
    353200, 
    361312, 
    366840, 
    371710, 
    375220, 
    379140, 
    381640, 
    388060, 
    391330, 
    395820, 
    400320, 
    405460, 
    409020, 
    414110, 
    419480, 
    424380
  ], 
  "end": [
    3100, 
    5020, 
    7740, 
    12410, 
    17660, 
    21140, 
    27380, 
    33560, 
    36740, 
    39740, 
    43420, 
    46980, 
    49380, 
    53760, 
    57920, 
    63660, 
    70020, 
    74540, 
    77420, 
    79420, 
    82280, 
    87500, 
    90600, 
    92740, 
    96380, 
    99480, 
    108576, 
    110880, 
    112360, 
    117540, 
    124200, 
    127300, 
    130670, 
    135580, 
    138540, 
    140880, 
    143320, 
    149920, 
    155240, 
    159950, 
    161840, 
    164460, 
    170200, 
    174320, 
    178520, 
    184940, 
    192940, 
    196780, 
    199400, 
    206670, 
    210200, 
    216150, 
    217500, 
    227488, 
    232400, 
    236190, 
    240240, 
    244140, 
    251690, 
    256570, 
    260860, 
    267270, 
    275520, 
    282320, 
    285400, 
    286940, 
    292260, 
    295770, 
    299900, 
    305560, 
    312890, 
    322450, 
    324570, 
    329980, 
    333700, 
    338570, 
    343070, 
    347150, 
    353130, 
    361152, 
    366750, 
    369420, 
    375130, 
    378940, 
    381550, 
    388000, 
    391240, 
    395530, 
    400170, 
    405360, 
    408930, 
    414020, 
    419400, 
    424110, 
    430660
  ], 
  "text": [
    "Let's do a quick review of", 
    "the previous module where we you learn", 
    "to build a Multi-layer Perceptron.", 
    "You took an image of a handwritten digit three here.", 
    "And then flattened it out into an array.", 
    "And used it as an input into your deep model.", 
    "All the image pixels were connected to", 
    "their corresponding nodes in the model here.", 
    "We then layered this first layer", 
    "and output of that layer was fed to the second layer", 
    "and the final output node had", 
    "ten categories which spelled out", 
    "one for each digit what they meant.", 
    "In this case, we were learning", 
    "for the first layer a set of weights and biases.", 
    "So in total there were six sets of parameters,", 
    "three sets of weights and biases. Okay!", 
    "The fact that all the pixels", 
    "were connected to the nodes", 
    "that were in the next layer", 
    "makes it a fully connected Network.", 
    "So in our case with n hidden nodes", 
    "the first layer had 400 such", 
    "but it could be anything arbitrary", 
    "if you build the entire network", 
    "it would have for this particular layer itself", 
    "you'll have 784 times n for the weights and n biases.", 
    "These are the total number of parameters", 
    "for this fully connected layer.", 
    "Now we want to do away with this flattening", 
    "may I ask, Why should we consider flattening out these image?", 
    "Does it make sense? Other than the convenience", 
    "of doing some algebraic manipulations.", 
    "The fact that a pixel within an image", 
    "is adjacent to another pixel", 
    "in all the directions and when you flatten it", 
    "that adjacency information is lost.", 
    "That doesn't make sense. So what we would like", 
    "to do instead is to see if we can devise", 
    "a scheme where we can take the image", 
    "and process it in such a way", 
    "that doesn't require this flattening.", 
    "So we take an image here", 
    "and we consider a weight matrix", 
    "say of size 3 by 3", 
    "instead of flattened weight vector here.", 
    "Okay! of length 784, if we did that and overlaid on top of this", 
    "region in the image we could do a dot product", 
    "between the weights and the corresponding pixel", 
    "values in the image, add the wires and that would be my output value", 
    "for that particular patch of the image.", 
    "And this would have taken into account the spacial adjacency", 
    "between the pixels,", 
    "and the number of parameters for this particular patch would be ten,", 
    "three times three for the weights and one for the bias.", 
    "Now note that this patch we will use as 3 by 3 but it doesn't", 
    "have to be it can be anything that you choose it's a parameter in your network.", 
    "In order to build the equivalent of a fully connected network", 
    "with this schema of running a patch or we'll call it a kernel or a filter", 
    "you can now go through and scan the", 
    "kernel across the entire image in a zigzag fashion.", 
    "And moving from here to there, there are 28 minus 2 steps", 
    "and you can repeat that steps along all the rows in the image", 
    "and when you do that you would have 28, minus two times 28 minus 2", 
    "output node and those have 10 parameters each.", 
    "So your network would have", 
    "6,760 parameters. Now we'll talk a lot about these number of", 
    "parameters because for these small images it may not make much of a", 
    "difference but for larger data set it can make a big difference.", 
    "So let's calculate what does it mean with respect to larger images", 
    "200 by 200 pixels that's not a whole lot that would be something like", 
    "40,000 pixels and in your cameras today you get image resolutions", 
    "that are in the order of megapixels.", 
    "Let's see what happens with this relatively small size image", 
    "of 200 by 200 pixels", 
    "with the filter size of 3 by 3 which is a very tiny patch", 
    "and you can say that when we slide the", 
    "kernel by one spot that is the stripe and we will have", 
    "five layers in my network and number of filters say are 20 per layer.", 
    "If we do the math it comes down to a hoping 39 million parameters.", 
    "Now 39 [Inaudible] million parameters is a lot of parameters,", 
    "for a small network.", 
    "What do we do with this small set of image now", 
    "which is generating this huge set of parameters.", 
    "There is a big problem because", 
    "this would lead to over fitting. We have to fit", 
    "these many parameters to our data set", 
    "and that too for a small Kernel size", 
    "with a relatively small image size.", 
    "And the layers being 5 which may sound a lot", 
    "to you but you will see later on that many practical architectures", 
    "would have way more than 5 layers.", 
    "And the number of filters I have set it to 20 but they", 
    "can be much larger too. How can we make it happen?", 
    "This is the motivation for Convolution Networks."
  ]
}