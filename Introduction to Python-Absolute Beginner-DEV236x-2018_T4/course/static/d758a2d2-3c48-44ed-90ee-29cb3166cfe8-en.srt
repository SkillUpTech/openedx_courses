0
00:00:02,080 --> 00:00:05,320
We will introduce you to the validation workflow.

1
00:00:05,320 --> 00:00:08,930
The goal here is to select the final model such that

2
00:00:08,930 --> 00:00:14,310
the loss observed during training and the loss observed

3
00:00:14,310 --> 00:00:19,450
on data samples that is not seen during training, are comparable.

4
00:00:19,450 --> 00:00:24,030
As we proceed along the training, which is the blue line

5
00:00:24,030 --> 00:00:29,860
here and find out our different model parameters and one and two

6
00:00:29,860 --> 00:00:35,610
and then we take a different set and called the validation set

7
00:00:35,610 --> 00:00:40,610
which is outside of the training datum and measure the loss

8
00:00:40,610 --> 00:00:44,971
using those parameters here and compute the corresponding loss.

9
00:00:46,070 --> 00:00:51,810
I'm marking my training loss with my blue circles here and

10
00:00:51,810 --> 00:00:54,910
then the corresponding validation loss,

11
00:00:54,910 --> 00:01:00,840
now we go back and choose our final model parameters.

12
00:01:00,840 --> 00:01:05,890
Here, the loss that we'd see in a data set that is not

13
00:01:05,890 --> 00:01:10,800
part of the training set to have the least validation error and

14
00:01:10,800 --> 00:01:12,520
that becomes our final model.

15
00:01:13,770 --> 00:01:15,660
I went to into a little bit more details here

16
00:01:15,660 --> 00:01:18,480
to explain you the process of the model selection.

17
00:01:18,480 --> 00:01:21,090
We will assume this workflow is

18
00:01:21,090 --> 00:01:24,610
already well understood as machine learning basics, and

19
00:01:24,610 --> 00:01:27,670
we will not be repeating the same workflow, and

20
00:01:27,670 --> 00:01:31,450
focus mostly on training, testing, and prediction.

21
00:01:33,320 --> 00:01:36,520
This is going to be considered as a given as we go into

22
00:01:36,520 --> 00:01:40,390
the labs, and moving forward into our further lectures,

23
00:01:40,390 --> 00:01:43,230
where we'll spend very little time explaining to you,

24
00:01:43,230 --> 00:01:45,490
how this final model is selected.

25
00:01:47,000 --> 00:01:50,870
Now that the final model is selected, we can take the test

26
00:01:50,870 --> 00:01:53,610
data, which is different from the training data.

27
00:01:53,610 --> 00:01:54,680
So this is the test data.

28
00:01:56,150 --> 00:02:01,430
We sample some data from our test database.

29
00:02:01,430 --> 00:02:05,770
And measure its performance on the final model.

30
00:02:05,770 --> 00:02:09,430
So the final model say it was the m10 say it,

31
00:02:09,430 --> 00:02:10,950
I'm just making it up here.

32
00:02:10,950 --> 00:02:14,100
So say the 10 estimates of our slope and

33
00:02:14,100 --> 00:02:16,529
bias of the intercept in that case.

34
00:02:17,960 --> 00:02:21,650
So let's say we pick up the 10th slope and

35
00:02:21,650 --> 00:02:26,080
the 10th value of the intercept and use that to measure what

36
00:02:26,080 --> 00:02:31,730
the test error is going to be so this is gonna report test error.

37
00:02:33,620 --> 00:02:36,620
In the context of the solar panel it's gonna be

38
00:02:36,620 --> 00:02:41,300
the difference between the estimated value for

39
00:02:41,300 --> 00:02:45,002
this particular test sample using the parameters

40
00:02:45,002 --> 00:02:48,610
here are gonna be m10 and b10.

41
00:02:48,610 --> 00:02:49,243
It's fixed,

42
00:02:49,243 --> 00:02:52,160
we have already learned that during training phase.

43
00:02:52,160 --> 00:02:56,560
And you'll continue to measure the test error for

44
00:02:56,560 --> 00:03:00,430
several samplings of data from the test database and

45
00:03:00,430 --> 00:03:01,770
report an average error.

