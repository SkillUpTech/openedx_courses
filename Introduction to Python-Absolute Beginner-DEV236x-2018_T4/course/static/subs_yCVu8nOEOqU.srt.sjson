{
  "start": [
    640, 
    5690, 
    7930, 
    10923, 
    12393, 
    15766, 
    18190, 
    21130, 
    23650, 
    25790, 
    31620, 
    36590, 
    39960, 
    42940, 
    46680, 
    49429, 
    52488, 
    57790, 
    59290, 
    64460, 
    69810, 
    73458, 
    77110, 
    78323, 
    83376, 
    88560, 
    93080, 
    97000, 
    100340, 
    104490, 
    107800, 
    111130, 
    115800, 
    119000, 
    120480, 
    123790, 
    126990, 
    131217, 
    134167, 
    137920, 
    143090, 
    146190, 
    149990, 
    155560, 
    160836, 
    168650, 
    170920, 
    174330, 
    178330, 
    183820, 
    185900, 
    187650, 
    192510, 
    196360, 
    199910, 
    203450, 
    209640, 
    212157, 
    214890, 
    217650, 
    222200, 
    224400, 
    225800, 
    228990, 
    231560, 
    234640, 
    238090, 
    243170, 
    247060, 
    249207, 
    252530, 
    257190, 
    259700, 
    262490, 
    266060, 
    269690, 
    271720, 
    275148, 
    278523, 
    279657, 
    284450, 
    288250, 
    290860, 
    293610, 
    297300, 
    301260, 
    304290, 
    307070, 
    311410, 
    315140, 
    318370, 
    321090, 
    327160, 
    330950, 
    337018, 
    342080, 
    350700, 
    355335, 
    358850, 
    362520, 
    366190, 
    369150, 
    373420, 
    377680, 
    382140, 
    385840, 
    389090, 
    394140, 
    399110, 
    404220, 
    407570, 
    411640, 
    415900, 
    420460, 
    423800, 
    425410, 
    428770, 
    434360, 
    440540, 
    444660, 
    447060, 
    449830, 
    454620, 
    457480, 
    461620, 
    464390, 
    466900, 
    469820, 
    473700, 
    476955, 
    480139
  ], 
  "end": [
    3780, 
    7930, 
    10923, 
    12393, 
    15766, 
    18190, 
    21130, 
    23650, 
    25790, 
    31620, 
    36590, 
    39960, 
    42940, 
    46680, 
    49429, 
    52488, 
    56700, 
    59290, 
    64460, 
    69810, 
    73458, 
    77110, 
    78323, 
    83376, 
    88560, 
    93080, 
    97000, 
    100340, 
    104490, 
    107800, 
    111130, 
    115800, 
    119000, 
    120480, 
    123790, 
    126990, 
    131217, 
    134167, 
    137920, 
    142040, 
    146190, 
    148000, 
    155560, 
    160836, 
    167540, 
    170920, 
    174330, 
    178330, 
    181370, 
    185900, 
    187650, 
    191270, 
    196360, 
    199910, 
    201820, 
    209640, 
    212157, 
    214890, 
    217650, 
    221165, 
    224400, 
    225800, 
    228990, 
    231560, 
    234640, 
    236098, 
    243170, 
    245940, 
    249207, 
    252530, 
    257190, 
    259700, 
    262490, 
    266060, 
    269690, 
    271720, 
    275148, 
    278523, 
    279657, 
    284450, 
    288250, 
    290860, 
    293610, 
    297300, 
    301260, 
    304290, 
    307070, 
    311410, 
    315140, 
    318370, 
    321090, 
    323810, 
    330950, 
    337018, 
    342080, 
    347060, 
    354200, 
    358850, 
    362520, 
    366190, 
    369150, 
    371580, 
    377680, 
    382140, 
    385840, 
    389090, 
    391400, 
    399110, 
    404220, 
    407570, 
    411640, 
    415900, 
    420460, 
    423800, 
    425410, 
    428770, 
    434360, 
    440540, 
    444660, 
    447060, 
    448330, 
    454620, 
    457480, 
    461620, 
    464390, 
    466900, 
    469820, 
    473700, 
    476955, 
    480139, 
    482058
  ], 
  "text": [
    "Let's review a few popular convolutional networks.", 
    "The first one is LeNet.", 
    "This was the first successful convolutional neural net", 
    "by Yann LeCun in 1990.", 
    "So you can see that convolutional neural nets have", 
    "been placed for a long time.", 
    "So you can see here that it used a bunch of", 
    "convolutional operations combined with", 
    "sub sampling which we didn't talk about but", 
    "sub sampling effectively reduces the size of the image by picking", 
    "every alternate whatever number of pixels you want to try so", 
    "it's equivalent to strike but you pick every other pixel if", 
    "you want to down sample by a size of two.", 
    "And then you connect it to a whole bunch of full connections.", 
    "Full connections is equivalent to our dense layers and", 
    "you can predict the digits just like we have been doing here.", 
    "You can see that the output layer has, is an array of ten.", 
    "The next one which is AlexNet.", 
    "This was by far the one that really revolutionized and", 
    "made deep learning, popular and rotted to the forefront.", 
    "It was developed by Alex Krizhevsky,", 
    "Ilya Sutskever and Geoffrey Hinton.", 
    "In 2012,", 
    "ImageNet challenge which is challenge around every year,", 
    "which has a large number of images and with label data sets.", 
    "The original image in that data set will have 1,000 labels.", 
    "And you've seen that in the introductory slides how", 
    "using this particular network that you see, we won't go into", 
    "the details of it, you can take an image, a natural seen image,", 
    "and classify it into the corresponding categories.", 
    "In this case you can see the leopard is classified as the top", 
    "category here, so the tag for this image would be leopard.", 
    "This is another way of representing how you can", 
    "depict your final results.", 
    "Instead of listing just the one top label,", 
    "you can list the top five categories.", 
    "And in this case with ImageNet using AlexNet data,", 
    "it outperformed the state of the art", 
    "by reducing the error from 26% to 16%.", 
    "In computer vision literature this is huge huge reduction.", 
    "This first introduced the use deeper", 
    "bigger stacked convolutional layers.", 
    "GoogLeNet was the winner of the challenge, ILSVRC challenge,", 
    "the same challenge that was won by AlexNet two years before.", 
    "GoogLeNet won it in 2014 by Szegedy et al from Google.", 
    "It introduced the inception module.", 
    "The key contribution of this module was the dramatic", 
    "reduction in parameters from 60 million to 4 million.", 
    "It used average pooling instead of fully connected layers.", 
    "The next one was the VGGNet,", 
    "which was also very very popular.", 
    "It was the runner up in the same year by Simonyan and Zisserman.", 
    "It showed depth of network is key to performance.", 
    "It had 16 convolution/fully connected layers,", 
    "an extremely homogeneous architecture.", 
    "It had a repeating set of 3 by 3 convolutions and 2 by 2 pooling.", 
    "It's more expensive to evaluate and", 
    "requires a large amount of memory.", 
    "It has roughly 140 million", 
    "parameters compared to 60 million from the AlexNet.", 
    "Most of the parameters however are in the fully", 
    "connected layer.", 
    "And later on people have found out that if these are removed,", 
    "they do not cause a significant performance drop.", 
    "So thereby reducing the number of parameters", 
    "in the VGGNet module.", 
    "ResNet, this was a winner of the ILSVRC 2015,", 
    "by Kaiming He from Microsoft.", 
    "It was the state of-the-art,", 
    "as of May 2016 and a default choice.", 
    "The original implementation had 152 layers and", 
    "it introduced the concept of residual learning.", 
    "These concept are fairly advanced and", 
    "would be part of a future offerings from the course.", 
    "You can see that these networks that we have designed.", 
    "The framework that you have learned so", 
    "far enables us to create very, very, very deep architecture,", 
    "which is foundational to a lot of the practical applications.", 
    "So now quickly,", 
    "let's review some of the more advanced applications.", 
    "So one of the applications is coloring grayscale images.", 
    "You can give that net grayscale image,", 
    "it will automatically generate a colored version of it.", 
    "You can read more about this in the papers that are cited here.", 
    "This one generates visually indicated sounds in a video.", 
    "So if you hit this kettle with a stick,", 
    "it would emit certain sounds.", 
    "You can train a machine learning model using techniques we have", 
    "talked so far which would learn that automatically and", 
    "if you feed a video without sound here", 
    "it can automatically generate that sound that", 
    "would have been generated if the kettle was hit with a stick.", 
    "Automated image captioning is also another popular application", 
    "where you give the input image as this picture which is a man", 
    "flying a kite, and the output of the model", 
    "would be a text describing what is being shown in the image.", 
    "Another application is neuro artistic painting.", 
    "These allows you to take any arbitrary picture and", 
    "get it rendered in the style of your favourite", 
    "painters like Picasso or Van Gogh or whoever it might be.", 
    "You can learn about this technique about GitHub site", 
    "with the tutorial that we have, if you're curious.", 
    "Some more advanced applications are in generating handwriting.", 
    "So the first line here is the data that is provided,", 
    "the handwriting that is provided by a person.", 
    "And rest of these are the ones that are generated by", 
    "the machine, and some of these look pretty neat.", 
    "If that's not enough, there's image generation which allows", 
    "you to generate images that are not real,", 
    "that means the original image sent was", 
    "used to train a model in such a way that at a later state you", 
    "could generate this arbitrary set of images as shown here.", 
    "These are call GAN, general adversarial networks.", 
    "And you can learn about these advance techniques", 
    "in our Github site.", 
    "Tutorial where there are more advanced techniques available to", 
    "you however for this course these are just to kindle your", 
    "curiosity and build a repertoire of technologies that we will be", 
    "introducing at the later stage but for the foundational course,", 
    "we would limit ourselves to the material that we have so", 
    "far introduced in this video.", 
    "In conclusion, CNNs are widely used in computer vision", 
    "with increasing popularity for text processing.", 
    "We didn't talk about text processing at all in this video,", 
    "but text processing is also taking advantage of", 
    "convolution operations increasingly.", 
    "Convolutions allow for deeper architectures that", 
    "affects performance it improves the performance quite a bit.", 
    "Different CNNS of varying complexity can be easily built", 
    "using the toolkit that we have and you'll be using it for", 
    "doing your homework exercises."
  ]
}