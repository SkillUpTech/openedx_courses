{"start":[0,3900,6145,9030,12116,14000,15345,16620,18750,22445,23780,26215,28520,30080,35480,36800,38970,40910,43755,45320,47255,48975,50870,54435,57080,60095,62330,63950,65690,67640,69110,71315,73640,76370,78340,79700,81195,84230,85970,87995,90035,91720,94325,95825,98613,99860,101360,103340,105350,108035,109460,113030,115760,118190,120230,122615,124245,128720,130640,133780,135400,137180,139340,142025,143685,145777,147230,148760,150065,152000,156320,157370,160205,162335,165389,166910,170115,171885,174660,177545,180804,183190,186510,189220,191920,193210,194880,196790],"end":[3900,6145,9030,12116,14000,15345,16620,18750,22445,23780,26215,28520,30080,35480,36800,38970,40910,43755,45320,47255,48975,50870,54435,57080,60095,62330,63950,65690,67640,69110,71315,73640,76370,78340,79700,81195,84230,85970,87995,90035,91720,94325,95825,98613,99860,101360,103340,105350,108035,109460,113030,115760,118190,120230,122615,124245,128720,130640,133780,135400,137180,139340,142025,143685,145777,147230,148760,150065,152000,156320,157370,160205,162335,165389,166910,170115,171885,174660,177545,180804,183190,186510,189220,191920,193210,194880,196790,200650],"text":["One of the more exciting aspects when working with","Cosmos DB and Apache Spark","is the idea of stream processing changes,","by combining Cosmos DB change feed","and Apache Spark together.","This is a wiki page that actually","contains all this information,","but we're going to do quick demo using","Jupyter Notebook, within HDInsight.","And so this notebook,","which you can download and use yourself.","Basically the basic constructs are here,","you've got a Twitter source,","which is being used to send data into Cosmos DB.","The information will show up","within the change feed itself,","and then Spark is able to go ahead,","and process inquiry that information as well.","So, let's go ahead and show it.","So, first things first,","we're going to go ahead and run the jar","similar to the previous session,","where we talked about running the change the connector.","So, these are the jars which we've already uploaded,","and we're going to go ahead and configure that.","And in this case the change feed","is a little slightly different.","We're going to add some additional variables","like rolling change feed,","start from the beginning,","use next token, things of that nature.","But overall, it's very similar in terms of","your configuration just like you had used before,","which is you indicate your endpoint,","your master key, your database,","and things of that nature.","The main difference will be the fact that you also","include information that's specific","to the change feed itself.","But now that once that's up and running,","it's back to Spark.","And so we went ahead and read the feed,","which is you can see right here,","the spark.read to read the information.","And when we started","the process there was","only one tweet that we were actually recording,","because there's only one tweet that","was ingested by Cosmos DB,","and then showed up in the change feed.","But over time, more and more tweets are going to show up.","So for example, this initially was an eight.","And so if I go and run this query right now,","it's going to be a different number,","because as more data comes through,","there are more tweets that will show up.","Now in this case there are 128 tweets that have showed up","ever since we started","this notebook against the Cosmos DB change feed.","And so to get an idea here's","a look at some of the tweets that you have there.","But the more interesting aspect is,","can we determine the top 10 hashtags","for the tweets that have come in?","And so far this is what the look is.","Most of them are big data,","and then you've got AI,","and you have data science,","and machine learning, and so forth and so forth.","But as I rerun this query, as more information,","more tweets are coming","in through the Cosmos DB change feed,","Spark is processing this information.","And now do you have a slightly different view?","Why? Because we refreshed","the information ever since the last time we rerun it.","There's actually a new set of information,","so now there's a little less tweets to look at.","But over time, we're going to run this again,","you'll see that that number starts increasing.","So, this is the way the change feed works.","And this is the way Spark can interact with it.","So, play with this notebook yourself as you can tell.","It's actually running over it's real time.","So, the numbers are changing","as you're playing with the data.","So, again, you can go download","the notebook and try it out yourself."]}